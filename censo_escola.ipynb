{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5445be4e-94f0-4627-a54e-42bb704db3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cde12fc-3849-4658-b2ac-0b169fdd09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:42: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_school_census_final = pd.read_csv(\"data/microdados_ed_basica_2022/dados/microdados_ed_basica_2022.csv\",encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus Rafalski\\AppData\\Local\\Temp\\ipykernel_14396\\3332641533.py:48: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "non_value_columns = np.array([\n",
    "    {\"name\": 'DT_ANO_LETIVO_INICIO'},\n",
    "    {\"name\": 'DT_ANO_LETIVO_TERMINO'},\n",
    "    {\"name\": 'NO_ENTIDADE'},\n",
    "    {\"name\": 'NO_MUNICIPIO'},\n",
    "    {\"name\": 'SG_UF'},\n",
    "    {\"name\": 'NO_REGIAO'},\n",
    "    {\"name\": 'NU_ANO_CENSO'},   \n",
    "    {\"name\": \"DS_ENDERECO\"},\n",
    "    {\"name\": \"NU_ENDERECO\"},\n",
    "    {\"name\": \"DS_COMPLEMENTO\"},\n",
    "    {\"name\": \"NO_BAIRRO\"},\n",
    "    {\"name\": \"NU_DDD\"},\n",
    "    {\"name\": \"NU_TELEFONE\"},\n",
    "    {\"name\": \"TP_DEPENDENCIA\"},\n",
    "    {\"name\":\"TP_SITUACAO_FUNCIONAMENTO\"},\n",
    "    { \"name\":\"TP_CATEGORIA_ESCOLA_PRIVADA\"},\n",
    "    { \"name\":\"TP_LOCALIZACAO\"},\n",
    "    {\"name\":\"IN_COZINHA\"},\n",
    "    {\"name\":\"IN_ESGOTO_INEXISTENTE\"},\n",
    "    {\"name\":\"IN_ENERGIA_INEXISTENTE\"},\n",
    "    {\"name\":\"IN_AREA_VERDE\"},\n",
    "    {\"name\":\"IN_BANHEIRO\"},\n",
    "    {\"name\":\"IN_DESPENSA\"},\n",
    "    {\"name\":\"IN_SECRETARIA\"},\n",
    "    {\"name\":\"IN_TRATAMENTO_LIXO_INEXISTENTE\"},\n",
    "    {\"name\":\"IN_REFEITORIO\"},\n",
    "    {\"name\":\"TP_DEPENDENCIA\"},\n",
    "    {\"name\":\"IN_BIBLIOTECA\"}\n",
    "])\n",
    "columns = [x['name'] for x in non_value_columns]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_school_census_final = pd.read_csv(\"data/microdados_ed_basica_2022/dados/microdados_ed_basica_2022.csv\",encoding=\"ISO-8859-1\", sep = ';')\n",
    "df_school_census_final = df_school_census_final[columns]\n",
    "\n",
    "for year in range(2012,2022):\n",
    "    csv_file = f'data/microdados_ed_basica_{year}/dados/microdados_ed_basica_{year}.csv'\n",
    "    df_current = pd.read_csv(csv_file,encoding=\"ISO-8859-1\", sep = ';')\n",
    "    df_current = df_current[columns]\n",
    "    df_school_census_final = pd.concat([df_school_census_final,df_current])\n",
    "    \n",
    "#df_school_census_final.to_csv(r'C:\\Users\\Matheus Rafalski\\Downloads\\export_dataframe.csv', index=False)\n",
    "\n",
    "\n",
    "#df_school_census_columns = pd.read_csv(\"Downloads/export_dataframe.csv\",encoding=\"utf8\", sep = ',')\n",
    "df_school_census_columns = df_school_census_final\n",
    "\n",
    "columns = np.array([\n",
    "    {\"name\": 'IN_COZINHA', \"1\": 80, \"0\":0},\n",
    "    {\"name\": 'IN_BIBLIOTECA', \"1\": 100, \"0\":0},\n",
    "    {\"name\": 'IN_ESGOTO_INEXISTENTE', \"1\": 0, \"0\":100},\n",
    "    {\"name\": 'IN_ENERGIA_INEXISTENTE', \"1\": 0, \"0\":100},\n",
    "    {\"name\": 'IN_AREA_VERDE', \"1\": 80, \"0\":0},\n",
    "    {\"name\": 'IN_BANHEIRO', \"1\": 100, \"0\":0},\n",
    "    {\"name\": 'IN_DESPENSA', \"1\": 80, \"0\":0},\n",
    "    {\"name\": 'IN_SECRETARIA', \"1\": 100, \"0\":0},\n",
    "    {\"name\": 'IN_TRATAMENTO_LIXO_INEXISTENTE', \"1\": 0, \"0\":80},\n",
    "    {\"name\": 'IN_REFEITORIO', \"1\": 80, \"0\":0},\n",
    "])\n",
    "\n",
    "result = np.concatenate((columns, non_value_columns))\n",
    "\n",
    "\n",
    "df_school_census_columns.dropna(axis=0, subset=['DT_ANO_LETIVO_INICIO'], inplace=True)\n",
    "df_school_census_columns = df_school_census_columns.replace('',np.nan)\n",
    "df_school_census_columns = df_school_census_columns[map(lambda column: column['name'], non_value_columns)]\n",
    "df_school_census_columns = df_school_census_columns[df_school_census_columns[\"DT_ANO_LETIVO_INICIO\"] != \"0\"]\n",
    "\n",
    "\n",
    "df_school_census_columns = df_school_census_columns.fillna(value=df_school_census_columns.mode().iloc[0])\n",
    "# Iterando sobre as colunas do dataframe\n",
    "for column in columns:\n",
    "    col = column['name']\n",
    "    df_school_census_columns[col] = df_school_census_columns[col].astype(int)\n",
    "\n",
    "def transform_situacao_funcionamento(x):\n",
    "    if x == 1:\n",
    "        return \"Ativa\"\n",
    "    elif x == 2:\n",
    "        return \"Paralisada\"\n",
    "    else: \n",
    "        return \"Extinta\"\n",
    "    \n",
    "\n",
    "df_school_census_columns[\"TP_SITUACAO_FUNCIONAMENTO\"] = df_school_census_columns[\"TP_SITUACAO_FUNCIONAMENTO\"].apply(transform_situacao_funcionamento)\n",
    "def transform_localizacao(x):\n",
    "    if x == 1:\n",
    "        return \"Urbana\"\n",
    "    elif x == 2:\n",
    "        return \"Rural\"\n",
    "    \n",
    "\n",
    "df_school_census_columns[\"TP_LOCALIZACAO\"] = df_school_census_columns[\"TP_LOCALIZACAO\"].apply(transform_localizacao)\n",
    "\n",
    "def transform_categoria_escola(x):\n",
    "    if x == 1:\n",
    "        return \"Particular\"\n",
    "    elif x == 2:\n",
    "        return \"Comunitária\"\n",
    "    elif x == 3:\n",
    "        return \"Confessional\"\n",
    "    elif x == 4:\n",
    "        return \"Filantrópica\"\n",
    "    else:\n",
    "        return \"Pública\"\n",
    "\n",
    "df_school_census_columns[\"TP_CATEGORIA_ESCOLA_PRIVADA\"] = df_school_census_columns[\"TP_CATEGORIA_ESCOLA_PRIVADA\"].apply(transform_categoria_escola)\n",
    "\n",
    "def transform_dependencia(x):\n",
    "    if x.eq(1).any():\n",
    "        return \"Federal\"\n",
    "    elif x.eq(2).any():\n",
    "        return \"Estadual\"\n",
    "    elif x.eq(3).any():\n",
    "        return \"Municipal\"\n",
    "    elif x.eq(4).any():\n",
    "        return \"Privada\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_school_census_columns[\"TP_DEPENDENCIA\"] = df_school_census_columns[\"TP_DEPENDENCIA\"].apply(transform_dependencia)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transform(x,column):\n",
    "    x_object = column\n",
    "    \n",
    "    if x == 1:\n",
    "        return  x_object['1']\n",
    "    elif x == 0:\n",
    "        return  x_object['0']\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# apply the function to each column using apply()\n",
    "\n",
    "for i in columns:\n",
    "    df_school_census_columns[i['name']] = df_school_census_columns[i['name']].apply(transform, column=i)\n",
    "\n",
    "print(\"Dataframe resultante:\")\n",
    "columns_name= [x['name'] for x in columns]\n",
    "\n",
    "estrutural_columns = df_school_census_columns[map(lambda column: column, columns_name)]\n",
    "estrutural_columns = estrutural_columns.assign(total=estrutural_columns.sum(axis=1))\n",
    "df_school_census_columns['total'] = estrutural_columns['total']\n",
    "df_school_census_columns.drop(columns_name, axis=1, inplace=True)\n",
    "\n",
    "# merge pib csv in df_school_census and then removce unused columns and apply etl\n",
    "\n",
    "df_school_census_columns = df_school_census_columns.drop(columns=['Código do Município', 'Região Metropolitana','Valor Agropecuária',\n",
    "                      'Valor Indústria','Valor Serviços','Valor Administração','Valor Total Bruto'\n",
    "                      ,'Impostos Liquidos','Valor Total','Atividade com maior valor adicionado bruto','Ano do Cesno'])\n",
    "\n",
    "df_school_census_columns.columns.values[1] = \"Região\"\n",
    "df_school_census_columns.columns.values[2] = \"Sigla\"\n",
    "df_school_census_columns.columns.values[3] = \"Estado\"\n",
    "df_school_census_columns.columns.values[4] = \"Município\"\n",
    "df_school_census_columns.columns.values[7] = \"Escola\"\n",
    "df_school_census_columns.columns.values[8] = \"Categoria\"\n",
    "\n",
    "def create_structure(x):\n",
    "    if x >= 800:\n",
    "        return \"Ótima\"\n",
    "    elif (x >= 600) & (x < 800):\n",
    "         return \"Boa\"\n",
    "    elif (x >= 400) & (x < 600):\n",
    "        return \"Média\"\n",
    "    elif (x >= 200) & (x < 400):\n",
    "        return \"Ruim\"\n",
    "    elif (x >= 0) & (x < 200):\n",
    "        return \"Precária\"\n",
    "    \n",
    "df_school_census_columns[\"Estrutura\"] = df_school_census_columns[\"total\"].apply(createStructure)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df_school_census_columns = df_school_census_columns.dropna(axis=0, subset=['DT_ANO_LETIVO_INICIO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c74175-ee11-4a4b-a044-997ad302a3a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'non_value_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_school_census_columns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloads/export_dataframe.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df_school_census_columns \u001b[38;5;241m=\u001b[39m df_school_census_columns[\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m column: column[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mnon_value_columns\u001b[49m)]\n\u001b[0;32m      4\u001b[0m df_school_census_columns \u001b[38;5;241m=\u001b[39m df_school_census_columns\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m      5\u001b[0m df_school_census_columns\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT_ANO_LETIVO_INICIO\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'non_value_columns' is not defined"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# df_school_census_columns = pd.read_csv(\"Downloads/export_dataframe.csv\",encoding=\"utf8\", sep = ',')\n",
    "\n",
    "# df_school_census_columns.to_csv(r'C:\\Users\\Matheus Rafalski\\Downloads\\csv_escolas.csv', index=False)\n",
    "# df_school_census_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80790687-edac-47f4-a82e-faa7ee5fa4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school_census_columns.drop(a, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32e1f61a-d163-4a85-b3e9-b31a36e5ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school_census_columns = df_school_census_columns.sort_values(by='total',ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
